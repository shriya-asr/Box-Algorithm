{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\achanta shriya\\anaconda3\\lib\\site-packages (1.24.9)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.9 in c:\\users\\achanta shriya\\anaconda3\\lib\\site-packages (from pymupdf) (1.24.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_coordinates(img_path):\n",
    "    img=cv2.imread(img_path,0)\n",
    "    img =cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    kernel_length = np.array(img).shape[1]//40\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "    img_temp1 = cv2.erode(img, vertical_kernel, iterations=3)\n",
    "    vertical_lines_img = cv2.dilate(img_temp1, vertical_kernel, iterations=3)\n",
    "    # cv2.imwrite(\"vertical_lines.jpg\",vertical_lines_img)\n",
    "\n",
    "\n",
    "    hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "    img_temp2 = cv2.erode(img, hori_kernel, iterations=3)\n",
    "\n",
    "    horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "    # cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)\n",
    "\n",
    "\n",
    "    alpha = 0.5\n",
    "    beta = 1.0 - alpha\n",
    "    # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "    img_bin = cv2.addWeighted(vertical_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "    img_bin = cv2.erode(~img_bin, kernel, iterations=2)\n",
    "    (thresh, img_bin) = cv2.threshold(img_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    \n",
    "\n",
    "    img_bin_tresh = cv2.adaptiveThreshold(img_bin ,255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    contours, _ = cv2.findContours(img_bin_tresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    contours = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[1])\n",
    "\n",
    "\n",
    "    table_coordinates = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w>50 and h>50:\n",
    "            table_coordinates.append([x, y+20, w-9, h-25])\n", #20 is subtracted to remove the heading row
    " \n",
    "    x, y, w, h = table_coordinates[0]\n",
    "    img_cropped = img[y:y+h, x:x+w]\n",
    "\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "    img_temp1 = cv2.erode(img, vertical_kernel, iterations=3)\n",
    "\n",
    "    vertical_lines_img = cv2.dilate(img_temp1, vertical_kernel, iterations=3)\n",
    "\n",
    "\n",
    "    contours, _ = cv2.findContours(vertical_lines_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",#to extract only the last column -containing a checklist
    "    vertical_lines_coordinates = []\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h1 = cv2.boundingRect(contour)\n",
    "        if h1>400:\n",
    "            vertical_lines_coordinates.append([x,y,w,h1])\n",
    "\n",
    "    vertical_lines_coordinates.sort()\n",
    "    # print(\"Vertical Lines Coordinates:\", vertical_lines_coordinates)\n",
    "\n",
    "    coordinates=[]\n",
    "    # Split image if enough lines are detected\n",
    "    if len(vertical_lines_coordinates) >= 2:\n",
    "\n",
    "        x1,y,w,h=table_coordinates[0]\n",
    "        x2=vertical_lines_coordinates[1][0]\n",
    "\n",
    "        img2=img[y:y+h,x2:x1+w]\n",
    "        coordinates=[(x2+4,y),(x2+4,y+h),(x1+w,y+h),(x1+w,y)]\n",#4 is added to remove the border of th elast column
    "        print(\"the actual coordinates are  [(486, 184), (484, 586), (538, 586), (540, 184)]\")\n",
    "        print(\"the obtained coordinates are\",coordinates)\n",
    "\n",
    "    else:\n",
    "        print(\"Not enough vertical lines detected to perform the image slicing.\")\n",
    "\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the actual coordinates are  [(486, 184), (484, 586), (538, 586), (540, 184)]\n",
      "the obtained coordinates are [(486, 181), (486, 587), (538, 587), (538, 181)]\n",
      "Cropped image saved for page  to: C:\\Users\\Achanta Shriya\\Desktop\\insurance\\tick\\page_1.png\n",
      "\n",
      "the actual coordinates are  [(486, 184), (484, 586), (538, 586), (540, 184)]\n",
      "the obtained coordinates are [(487, 180), (487, 586), (538, 586), (538, 180)]\n",
      "Cropped image saved for page  to: C:\\Users\\Achanta Shriya\\Desktop\\insurance\\tick\\page_2.png\n",
      "\n",
      "the actual coordinates are  [(486, 184), (484, 586), (538, 586), (540, 184)]\n",
      "the obtained coordinates are [(486, 182), (486, 587), (538, 587), (538, 182)]\n",
      "Cropped image saved for page  to: C:\\Users\\Achanta Shriya\\Desktop\\insurance\\tick\\page_3.png\n",
      "\n",
      "the actual coordinates are  [(486, 184), (484, 586), (538, 586), (540, 184)]\n",
      "the obtained coordinates are [(486, 182), (486, 588), (537, 588), (537, 182)]\n",
      "Cropped image saved for page  to: C:\\Users\\Achanta Shriya\\Desktop\\insurance\\tick\\page_4.png\n",
      "\n",
      "the actual coordinates are  [(486, 184), (484, 586), (538, 586), (540, 184)]\n",
      "the obtained coordinates are [(487, 182), (487, 587), (538, 587), (538, 182)]\n",
      "Cropped image saved for page  to: C:\\Users\\Achanta Shriya\\Desktop\\insurance\\tick\\page_5.png\n",
      "\n",
      "the actual coordinates are  [(486, 184), (484, 586), (538, 586), (540, 184)]\n",
      "the obtained coordinates are [(487, 182), (487, 587), (538, 587), (538, 182)]\n",
      "Cropped image saved for page  to: C:\\Users\\Achanta Shriya\\Desktop\\insurance\\tick\\page_6.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def crop_region_from_pdf_all_pages(pdf_path, input_folder,output_folder):\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    os.makedirs(input_folder,exist_ok=True)\n",
    "\n",
    "    # Open the PDF file\n",
    "\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "\n",
    "    for page_number in range(len(pdf_document)):\n",
    "\n",
    "        # Get the current page\n",
    "\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        pix = page.get_pixmap()\n",
    "        output_path = f\"C:\\\\Users\\\\Achanta Shriya\\\\Desktop\\\\insurance\\\\input_folder\\\\page-{page_number}.png\"\n",
    "        pix.save(output_path)\n",
    "        coordinates=[]\n",
    "        # Define the coordinates of the region to crop\n",
    "        coordinates=crop_coordinates(output_path)\n",
    "        #print(\"the coordinates are\",coordinates)\n",
    "\n",
    "        x0, y0 = coordinates[0]\n",
    "\n",
    "        x1, y1 = coordinates[1]\n",
    "\n",
    "        x2, y2 = coordinates[2]\n",
    "\n",
    "        x3, y3 = coordinates[3]\n",
    "\n",
    "        # Get the dimensions of the page\n",
    "\n",
    "        page_width = page.rect.width\n",
    "\n",
    "        page_height = page.rect.height\n",
    "\n",
    "        # Check if the coordinates are within the page boundaries\n",
    "\n",
    "        if x0 < 0 or x1 < 0 or x2 < 0 or x3 < 0 or y0 < 0 or y1 < 0 or y2 < 0 or y3 < 0:\n",
    "\n",
    "            print(f\"Error on page {page_number + 1}: Coordinates cannot be negative.\")\n",
    "\n",
    "            continue\n",
    "\n",
    "        if x0 > page_width or x1 > page_width or x2 > page_width or x3 > page_width:\n",
    "\n",
    "            print(f\"Error on page {page_number + 1}: X-coordinate exceeds page width.\")\n",
    "\n",
    "            continue\n",
    "\n",
    "        if y0 > page_height or y1 > page_height or y2 > page_height or y3 > page_height:\n",
    "\n",
    "            print(f\"Error on page {page_number + 1}: Y-coordinate exceeds page height.\")\n",
    "\n",
    "            continue\n",
    "        # Define the rectangle to crop\n",
    "\n",
    "        rect = fitz.Rect(x0, y0, x2, y2)\n",
    "\n",
    "        # Extract the region as a pixmap\n",
    "\n",
    "        pixmap = page.get_pixmap(matrix=fitz.Matrix(1, 1), clip=rect)\n",
    "\n",
    "        # Convert the pixmap to an image\n",
    "        image = Image.frombytes(\"RGB\", [pixmap.width, pixmap.height], pixmap.samples)\n",
    "\n",
    "        # Save the cropped image\n",
    "\n",
    "        output_image_path = os.path.join(output_folder, f\"page_{page_number + 1}.png\")\n",
    "\n",
    "        image.save(output_image_path)\n",
    "\n",
    "        print(f\"Cropped image saved for page  to: {output_image_path}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "pdf_path = \"C:\\\\Users\\\\Achanta Shriya\\\\Desktop\\\\insurance\\\\pdf.pdf\"\n",
    "output_folder = \"C:\\\\Users\\\\Achanta Shriya\\\\Desktop\\\\insurance\\\\tick\"\n",
    "input_folder=\"C:\\\\Users\\\\Achanta Shriya\\\\Desktop\\\\insurance\\\\input_folder\"\n",
    "\n",
    "#predefined coordinates"
    "#coordinates = [(462,617), (462, 633), (536, 633), (536, 618)]\n",
    "# coordinates for signature\n",
    "# coordinates = [(462,617), (462, 633), (536, 633), (536, 618)]\n",
    "# Coordinates for tick mark cells\n",
    "#coordinates = [(486, 184), (484, 586), (538, 586), (540, 184)]\n",
    "# coordinates for reference pdf \n",
    "\n",
    "# coordinates = (492, 173), (493, 591), (547, 592), (548, 174)\n",
    "\n",
    "# coordinates for reference pdf signature\n",
    "\n",
    "# (466, 624), (466, 641), (548, 641), (549, 624)\n",
    "\n",
    "crop_region_from_pdf_all_pages(pdf_path, input_folder,output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to C:\\Users\\Achanta Shriya\\Desktop\\insurance\\results.xlsx\n"
     ]
    }
   ],
   "source": [
    "def calculate_row_statistics(image_path, ranges):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Get the number of rows and columns\n",
    "\n",
    "    num_rows, num_cols = gray.shape\n",
    "\n",
    "    # Initialize lists to store averages\n",
    "\n",
    "    row_averages = []\n",
    "    # Calculate the average for each row\n",
    "\n",
    "    for i in range(num_rows):\n",
    "\n",
    "        row_average = np.mean(gray[i, :])\n",
    "\n",
    "        row_averages.append(row_average)\n",
    "    # Find the lowest average in each specified range and discard rows before and after\n",
    "\n",
    "    lowest_rows = []\n",
    "\n",
    "    for start, end in ranges:\n",
    "\n",
    "        range_averages = row_averages[start-1:end]  # Adjust range to be 0-based index\n",
    "\n",
    "        min_average = min(range_averages)\n",
    "\n",
    "        min_index = range_averages.index(min_average) + start  # +start to convert to correct index\n",
    "\n",
    "        if min_index > 1 and min_index < num_rows:\n",
    "\n",
    "            lowest_rows.append((min_index - 1, min_index, min_index + 1))\n",
    "\n",
    "        elif min_index == 1:\n",
    "\n",
    "            lowest_rows.append((min_index, min_index + 1))\n",
    "\n",
    "        elif min_index == num_rows:\n",
    "\n",
    "            lowest_rows.append((min_index - 1, min_index))\n",
    "\n",
    "    return lowest_rows\n",
    "\n",
    "# Function to crop the image based on row indices\n",
    "\n",
    "def crop_image(image, rows_to_crop):\n",
    "\n",
    "    cropped_images = []\n",
    "\n",
    "    num_rows, _ = image.shape[:2]\n",
    "\n",
    "    start_row = 0\n",
    "\n",
    "    for row_group in rows_to_crop:\n",
    "\n",
    "        for row in row_group:\n",
    "\n",
    "            if row - 1 > start_row:  # Ensure there is a range to crop\n",
    "\n",
    "                cropped_img = image[start_row:row - 1, :]  # Crop from start_row to row-1\n",
    "\n",
    "                cropped_images.append(cropped_img)\n",
    "\n",
    "            start_row = row + 1  # Update start_row to row + 1 to skip the discarded row\n",
    "\n",
    "    # Add the last cropped image from the last lowest row to the end of the page\n",
    "\n",
    "    if start_row < num_rows:\n",
    "\n",
    "        cropped_img = image[start_row:, :]\n",
    "\n",
    "        cropped_images.append(cropped_img)\n",
    "\n",
    "    return cropped_images\n",
    "\n",
    "# Function to create folders for each page and save cropped images\n",
    "\n",
    "def save_cropped_images(image_path, lowest_rows):\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    # Create a folder for the page\n",
    "\n",
    "    page_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "    page_folder = f\"cropped_images/{page_name}\"\n",
    "\n",
    "    os.makedirs(page_folder, exist_ok=True)\n",
    "    # Crop the image based on lowest row indices\n",
    "\n",
    "    cropped_images = crop_image(image, lowest_rows)\n",
    "\n",
    "    # Save each cropped image\n",
    "\n",
    "    cropped_image_paths = []\n",
    "\n",
    "    for i, cropped_img in enumerate(cropped_images):\n",
    "\n",
    "        save_path = os.path.join(page_folder, f\"cropped_image_reference{i+1}.png\")\n",
    "\n",
    "        cv2.imwrite(save_path, cropped_img)\n",
    "\n",
    "        cropped_image_paths.append(save_path)\n",
    "\n",
    "    return cropped_image_paths\n",
    "\n",
    "# Function to check for black regions in an image\n",
    "\n",
    "def check_black_region(image_path):\n",
    "\n",
    "    # Load the image\n",
    "\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Apply adaptive thresholding\n",
    "\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Calculate the average intensity of each row\n",
    "\n",
    "    row_averages = np.mean(image, axis=1)\n",
    "    # Sum the averages of all rows\n",
    "\n",
    "    sum_of_averages = np.sum(row_averages)\n",
    "\n",
    "    if sum_of_averages < 4000:\n",
    "\n",
    "        has_black_region = True\n",
    "\n",
    "    else:\n",
    "\n",
    "        has_black_region = False\n",
    "    return has_black_region\n",
    "\n",
    "# Function to process images in a folder and calculate row averages considering only 30% of the columns\n",
    "\n",
    "def process_images(folder_path, results):\n",
    "\n",
    "    # Initialize a DataFrame to store detailed results\n",
    "\n",
    "    detailed_results = []\n",
    "\n",
    "    # Iterate through all subfolders in the folder\n",
    "\n",
    "    for subfolder_name in os.listdir(folder_path):\n",
    "\n",
    "        subfolder_path = os.path.join(folder_path, subfolder_name)\n",
    "        # Check if the path is a directory\n",
    "\n",
    "        if os.path.isdir(subfolder_path):\n",
    "\n",
    "            # Initialize the list of results for the current page\n",
    "\n",
    "            page_results = [subfolder_name]\n",
    "\n",
    "            # Iterate through all files in the subfolder\n",
    "\n",
    "            for filename in os.listdir(subfolder_path):\n",
    "\n",
    "                # Check if the file is an image (you can add more extensions as needed)\n",
    "\n",
    "                if filename.endswith('.png') or filename.endswith('.jpg') or filename.endswith('.jpeg'):\n",
    "\n",
    "                    # Construct the full path to the image file\n",
    "\n",
    "                    image_path = os.path.join(subfolder_path, filename)\n",
    "                    # Load the image in grayscale\n",
    "\n",
    "                    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                    if image is None:\n",
    "\n",
    "                        print(f\"Error: Unable to load image {image_path}\")\n",
    "\n",
    "                        continue\n",
    "                    # Calculate the number of rows and columns\n",
    "\n",
    "                    num_rows, num_cols = image.shape\n",
    "\n",
    "                    # Consider only the first 30% of the columns\n",
    "\n",
    "                    thirty_percent_col = int(num_cols * 0.3)\n",
    "\n",
    "                    image_30_percent = image[:, :thirty_percent_col]\n",
    "\n",
    "                    # Set threshold for valid rows\n",
    "\n",
    "                    threshold = 245\n",
    "                    # Remove rows with average intensity greater than 245\n",
    "\n",
    "                    valid_rows = [row for row in range(image_30_percent.shape[0]) if np.mean(image_30_percent[row, :]) <= threshold]\n",
    "\n",
    "                    # If there are no valid rows, skip the image\n",
    "                    if not valid_rows:\n",
    "\n",
    "                        continue\n",
    "\n",
    "                    # Filter the first half based on valid rows\n",
    "\n",
    "                    mid_row = len(valid_rows) // 2\n",
    "\n",
    "                    first_half = image_30_percent[valid_rows[:mid_row], :]\n",
    "\n",
    "                    second_half = image_30_percent[valid_rows[mid_row:], :]\n",
    "                    # Calculate averages of both halves\n",
    "\n",
    "                    first_half_averages = [np.mean(first_half[row, :]) for row in range(first_half.shape[0])]\n",
    "\n",
    "                    second_half_averages = [np.mean(second_half[row, :]) for row in range(second_half.shape[0])]\n",
    "\n",
    "                    # Apply the filter: if valid row count is different and the difference of sums is between 0 and 100\n",
    "\n",
    "                    if len(first_half_averages) != len(second_half_averages):\n",
    "\n",
    "                        sum_first_half_averages = np.sum(first_half_averages)\n",
    "\n",
    "                        sum_second_half_averages = np.sum(second_half_averages)\n",
    "\n",
    "                        difference_of_sums = sum_second_half_averages - sum_first_half_averages\n",
    "\n",
    "\n",
    "                        if 0 < difference_of_sums < 100:\n",
    "\n",
    "                            # Remove the lowest intensity value from the second half\n",
    "\n",
    "                            if second_half_averages:\n",
    "\n",
    "                                min_intensity_index = second_half_averages.index(min(second_half_averages))\n",
    "\n",
    "                                del second_half_averages[min_intensity_index]\n",
    "\n",
    "                    # Sum up all the averages of both halves\n",
    "\n",
    "                    sum_first_half_averages = np.sum(first_half_averages)\n",
    "\n",
    "                    sum_second_half_averages = np.sum(second_half_averages)\n",
    "\n",
    "                    # Determine if \"yes\", \"no\", or \"no tick found\" based on the sums of averages\n",
    "\n",
    "                    result = \"No tick found\"\n",
    "\n",
    "                    if sum_first_half_averages < sum_second_half_averages:\n",
    "\n",
    "                        result = \"Yes\"\n",
    "\n",
    "                    elif sum_first_half_averages > sum_second_half_averages:\n",
    "\n",
    "                        result = \"No\"\n",
    "                    # Append the result to the page_results\n",
    "\n",
    "                    page_results.append(result)\n",
    "\n",
    "            # Append the results of the current page to the overall results\n",
    "\n",
    "            results.append(page_results)\n",
    "\n",
    "# Function to check for signature images and add to the results\n",
    "\n",
    "def check_signatures(signature_folder_path, results):\n",
    "\n",
    "    # Iterate through the results to check for signatures\n",
    "\n",
    "    for page_index, page_results in enumerate(results):\n",
    "\n",
    "        page_name = f'page_{page_index + 1}'\n",
    "\n",
    "\n",
    "        # Check for signature in the signature images folder\n",
    "\n",
    "        signature_found = False\n",
    "\n",
    "        \n",
    "        if os.path.exists(signature_folder_path) and os.path.isdir(signature_folder_path):\n",
    "\n",
    "            files_in_folder = os.listdir(signature_folder_path)\n",
    "\n",
    "            for filename in files_in_folder:\n",
    "\n",
    "                if filename.endswith('.png') or filename.endswith('.jpg') or filename.endswith('.jpeg'):\n",
    "\n",
    "                    signature_image_path = os.path.join(signature_folder_path, filename)\n",
    "\n",
    "                    if check_black_region(signature_image_path):\n",
    "\n",
    "                        signature_found = True\n",
    "        else:\n",
    "\n",
    "            print(f\"Folder does not exist: {signature_folder_path}\")\n",
    "        # Append \"True\" or \"False\" based on signature detection to the current page result\n",
    "\n",
    "        page_results.append(\"Yes\" if signature_found else \"No\")\n",
    "\n",
    "# Input parameters\n",
    "\n",
    "\n",
    "original_folder_path ='C:\\\\Users\\\\Achanta Shriya\\\\Desktop\\\\insurance\\\\tick'\n",
    "\n",
    "cropped_images_folder_path ='cropped_images'\n",
    "\n",
    "signature_folder_path ='C:\\\\Users\\\\Achanta Shriya\\\\Desktop\\\\insurance\\\\SIGN_unchanged'\n",
    "\n",
    "ranges = [(79, 99),(108, 135),(138, 158),(192, 212),(245, 265),(298, 318),(328, 348),(358, 360)]\n",
    "#actual--ranges = [(79, 99),(108, 128),(138, 158),(192, 212),(245, 265),(298, 318),(328, 348),(358, 378)]\n"
    "\n",
    "\n",
    "# Initialize a list to store the results\n",
    "\n",
    "results = []\n",
    "# Process each image in the original folder\n",
    "\n",
    "for filename in os.listdir(original_folder_path):\n",
    "\n",
    "    if filename.endswith('.png') or filename.endswith('.jpg'):  \n",
    "\n",
    "        image_path = os.path.join(original_folder_path, filename)\n",
    "\n",
    "        lowest_rows = calculate_row_statistics(image_path, ranges)\n",
    "\n",
    "        cropped_image_paths = save_cropped_images(image_path, lowest_rows)\n",
    "\n",
    "# Process all cropped images in the folder and calculate row averages considering only 30% of the columns\n",
    "\n",
    "process_images(cropped_images_folder_path, results)\n",
    "# Check for signatures and add to the results\n",
    "\n",
    "check_signatures(signature_folder_path, results)\n",
    "# Convert results to a DataFrame and transpose it\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "# Set the first column as the index (page names)\n",
    "\n",
    "df.set_index(0, inplace=True)\n",
    "# Transpose the DataFrame\n",
    "\n",
    "df = df.transpose()\n",
    "\n",
    "# Rename the columns with page numbers\n",
    "\n",
    "df.columns = [f'page_{i+1}' for i in range(len(results))]\n",
    "\n",
    "# Rename the index labels to 'check box x'\n",
    "\n",
    "df.index = df.index.map(lambda x: f\"check box {x}\")\n",
    "# Rename 'check box 10' to 'signature found?'\n",
    "\n",
    "if 'check box 10' in df.index:\n",
    "\n",
    "    df.rename(index={'check box 10': 'signature found?'}, inplace=True)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "\n",
    "excel_path = 'C:\\\\Users\\\\Achanta Shriya\\\\Desktop\\\\insurance\\\\results.xlsx'\n",
    "\n",
    "df.to_excel(excel_path, index=True)\n",
    "\n",
    "print(f\"Results saved to {excel_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
